{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7144211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbad45b",
   "metadata": {},
   "source": [
    "1. Data visualization\n",
    "2. Data pre-processing\n",
    "3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50daf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = ('./feedback-prize-english-language-learning/train.csv')\n",
    "test_data_path = ('./feedback-prize-english-language-learning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    corpus = pd.read_csv(path)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620e3b2",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133f5c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaaaf4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eab72c",
   "metadata": {},
   "source": [
    "### Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75586674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c54dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_data(data):\n",
    "    lowercase = np.char.lower(data)\n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-.,/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    no_punctuation = data\n",
    "    for i in symbols:\n",
    "        no_punctuation = np.char.replace(no_punctuation, i, ' ')\n",
    "        no_punctuation = np.char.replace(no_punctuation, \"'\", \"\")        \n",
    "        \n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2240bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_words(data):\n",
    "    newData = []\n",
    "    for i in data:\n",
    "        if i != str(i):\n",
    "            num = num2words(i)\n",
    "            newData.append(num)\n",
    "        else:\n",
    "            newData.append(i)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82fa7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in data if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc4ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(data):\n",
    "    a = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(i)\n",
    "        a.append(lemmatized_word)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996b7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanning(data):\n",
    "    df = data\n",
    "    # Loop through data and clean it.\n",
    "    for i in data['full_text']:\n",
    "       \n",
    "        ndata = tokenize_data(i)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        ndata = lowercase_data(ndata)\n",
    "        ndata = numbers_to_words(ndata)\n",
    "        ndata = remove_stop_words(ndata)\n",
    "        ndata = lemmatize_words(ndata)\n",
    "        ndata = numbers_to_words(ndata)\n",
    "        ndata = ' '.join(ndata)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        \n",
    "        df = df.replace(i, ndata)\n",
    "\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53525f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_validation(data):    \n",
    "    train_d, val_d = train_test_split(data, test_size=0.2, random_state=1)\n",
    "    train_d = pd.DataFrame(train_d)\n",
    "    val_d = pd.DataFrame(val_d)\n",
    "    return train_d, val_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbc3805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(data):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=100,\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.8,\n",
    "                                 ngram_range=(1,3))\n",
    "    vectors = vectorizer.fit_transform(data)\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    all_keywords = []\n",
    "    for i in denselist:\n",
    "        x = 0\n",
    "        keywords = []\n",
    "        for word in i:\n",
    "            if word > 0:\n",
    "                keywords.append(feature_names[x])\n",
    "            x=x+1\n",
    "        all_keywords.append(keywords)\n",
    "    \n",
    "            \n",
    "    \n",
    "    return vectors, denselist, feature_names, all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6eaf52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_pipeline(data):\n",
    "    dataf = load_data(data)\n",
    "\n",
    "    train_data, validation_data = split_test_validation(dataf)\n",
    "\n",
    "    clean_data = data_cleanning(train_data[:30])\n",
    "    vectors, denselist, feature_names, all_keywords = tf_idf(clean_data['full_text'])\n",
    "    y = train_data[['vocabulary', 'syntax']]\n",
    "    \n",
    "    # Convert vectoried data with keywords into a dataframe\n",
    "    data=[]\n",
    "    for i in range(len(all_keywords)):\n",
    "        data.insert(i, {'words':all_keywords[i],'vectors':denselist[i],})\n",
    "    dataframe = pd.DataFrame(data)\n",
    "\n",
    "    return dataframe, y, clean_data, vectors, denselist, feature_names, all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d9c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe:\n",
      "                                                 words  \\\n",
      "0   [friend, good, idea, important, nt, people, sc...   \n",
      "1   [agree, bad, better, change, example, feel, fi...   \n",
      "2   [agree, always, bad, best, better, change, cou...   \n",
      "3   [agree, always, bad, ca, ca nt, could, example...   \n",
      "4   [better, change, feel, going, good, make, many...   \n",
      "5   [activity, also, another, benefit, best, bette...   \n",
      "6   [agree, bad, class, come, day, different, get,...   \n",
      "7   [able, also, always, best, better, change, cla...   \n",
      "8   [activity, agree, also, another, benefit, ca, ...   \n",
      "9   [class, day, every, going, group, learn, lot, ...   \n",
      "10  [agree, also, always, class, come, day, every,...   \n",
      "11  [better, could, future, get, go, good, grade, ...   \n",
      "12  [agree, also, always, another, better, could, ...   \n",
      "13  [also, day, different, experience, get, good, ...   \n",
      "14  [able, agree, also, always, bad, best, come, d...   \n",
      "15  [also, better, class, could, different, exampl...   \n",
      "16  [bad, better, class, example, experience, fami...   \n",
      "17  [bad, better, class, every, get, grade, help, ...   \n",
      "18  [activity, also, another, benefit, best, class...   \n",
      "19  [always, best, better, class, future, go, goin...   \n",
      "20  [always, bad, change, come, day, every, experi...   \n",
      "21  [also, always, benefit, better, come, example,...   \n",
      "22  [able, activity, also, always, another, best, ...   \n",
      "23  [able, also, benefit, class, could, day, diffe...   \n",
      "24  [agree, always, bad, example, family, first, f...   \n",
      "25  [another, every, example, family, friend, get,...   \n",
      "26  [another, best, better, ca, ca nt, different, ...   \n",
      "27  [always, best, better, ca, ca nt, change, coul...   \n",
      "28  [able, activity, also, always, another, benefi...   \n",
      "29  [also, another, bad, best, ca, ca nt, day, exa...   \n",
      "\n",
      "                                              vectors  \n",
      "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1   [0.0, 0.0, 0.08135352689624402, 0.0, 0.0, 0.0,...  \n",
      "2   [0.0, 0.0, 0.05345836798376058, 0.0, 0.0450192...  \n",
      "3   [0.0, 0.0, 0.11259261738532989, 0.0, 0.0474091...  \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "5   [0.0, 0.06243642160918445, 0.0, 0.020392135200...  \n",
      "6   [0.0, 0.0, 0.05367828259692093, 0.0, 0.0, 0.0,...  \n",
      "7   [0.06915906403809816, 0.0, 0.0, 0.090351173102...  \n",
      "8   [0.0, 0.3610501674453485, 0.04854130468383931,...  \n",
      "9   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "10  [0.0, 0.0, 0.056480454931852726, 0.04573595315...  \n",
      "11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "12  [0.0, 0.0, 0.1646505888137117, 0.0888856345877...  \n",
      "13  [0.0, 0.0, 0.0, 0.10638726248722652, 0.0, 0.0,...  \n",
      "14  [0.2110636359634866, 0.0, 0.11350560320715941,...  \n",
      "15  [0.0, 0.0, 0.0, 0.3847250959376811, 0.0, 0.0, ...  \n",
      "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1797209332990...  \n",
      "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1103547172149...  \n",
      "18  [0.0, 0.05383221978666029, 0.0, 0.035163895550...  \n",
      "19  [0.0, 0.0, 0.0, 0.0, 0.0721742222717893, 0.0, ...  \n",
      "20  [0.0, 0.0, 0.0, 0.0, 0.2025591915798793, 0.0, ...  \n",
      "21  [0.0, 0.0, 0.0, 0.11166587512554103, 0.1161296...  \n",
      "22  [0.07333906128539554, 0.07333906128539554, 0.0...  \n",
      "23  [0.14609930212062633, 0.0, 0.0, 0.047716967832...  \n",
      "24  [0.0, 0.0, 0.06197194324126279, 0.0, 0.2087551...  \n",
      "25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.11256588592101303,...  \n",
      "26  [0.0, 0.0, 0.0, 0.0, 0.0, 0.15007953344696937,...  \n",
      "27  [0.0, 0.0, 0.0, 0.0, 0.07008959578581257, 0.0,...  \n",
      "28  [0.09651583585265194, 0.14477375377897791, 0.0...  \n",
      "29  [0.0, 0.0, 0.0, 0.18970113556109539, 0.0, 0.11...  \n",
      "y:\n",
      "       vocabulary  syntax\n",
      "2352         3.0     2.0\n",
      "3059         3.5     3.0\n",
      "1142         4.0     3.5\n",
      "1195         3.0     3.0\n",
      "2354         4.0     3.0\n",
      "...          ...     ...\n",
      "905          2.5     2.5\n",
      "3839         4.0     4.0\n",
      "1096         3.0     3.5\n",
      "235          3.0     2.5\n",
      "1061         3.0     3.0\n",
      "\n",
      "[3128 rows x 2 columns]\n",
      "clean:\n",
      "            text_id                                          full_text  \\\n",
      "2352  AEE8A576989C  dear friend name student name coming location ...   \n",
      "3059  DA00F2B25B8C  according author  world constantly trying make...   \n",
      "1142  589CEB00ED37  good behavior trying influence per swaying oth...   \n",
      "1195  5C9B1FB411EB  said positive attitude key success life   agre...   \n",
      "2354  AEF788DA28DE  think principal change school policy many stud...   \n",
      "3060  DA1ABE125640  working group sometime working alone hard   wo...   \n",
      "407   1F0A461A2589  school offer distance learning house student l...   \n",
      "137   0ABD502C5BF9  ever needed example learn something learn bett...   \n",
      "3757  F9BE4676CA35     student must participate least one extracur...   \n",
      "3712  F7DD6134C693  generation generation new technology   time ce...   \n",
      "1395  6B850987631D  school offer student distance learning option ...   \n",
      "1163  59E62F702421  student allowed want learn much profession   w...   \n",
      "2773  CB4C85EFAE67  author waldo emerson wrote statement quote say...   \n",
      "1813  88966ED00A28  program help older younger student   older stu...   \n",
      "1651  7D94F809823A  many people agree   use technology brings posi...   \n",
      "2099  9DCB91B1F18D  think student take art   muisc   drama class  ...   \n",
      "516   272CA21BAE13  parent think normal student choose career youn...   \n",
      "3716  F7E78C064324  people ask advice talk play sport homework   t...   \n",
      "2495  B9B02A6FB3F9  dear teacher   date   03 12 19 address   cente...   \n",
      "1549  770541C6A2C1  would like start life early   graduating privi...   \n",
      "220   109D8D4A91FC  may say impossbile impression left person   pe...   \n",
      "2941  D38A414FA051  many believe positive attitude key success lif...   \n",
      "3197  E07F7A913FB6  football manager olegunnar solksajer said    p...   \n",
      "982   4B174612FD60  imagine oneself student high school already st...   \n",
      "3169  DEDD5C568B4C  agree honest time need honest true friend   ne...   \n",
      "3071  DA8E64EC1304  think tecthnology helping every people world p...   \n",
      "1960  93EF5F755313  may concern   former british prime minister wi...   \n",
      "3214  E110443F5184     character choose make      therefore   opin...   \n",
      "2429  B4994C771190  think student would benefit able attend class ...   \n",
      "725   3814F9116CD1  well business want visit hospital pharmacy   t...   \n",
      "\n",
      "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
      "2352       2.5     2.0         3.0          2.5      2.0          2.5  \n",
      "3059       3.5     3.0         3.5          3.5      2.5          3.0  \n",
      "1142       3.5     3.5         4.0          3.5      3.0          3.0  \n",
      "1195       3.5     3.0         3.0          3.5      3.0          3.5  \n",
      "2354       3.0     3.0         4.0          3.0      3.0          3.5  \n",
      "3060       3.0     3.0         3.0          3.0      2.0          2.5  \n",
      "407        3.0     3.0         3.0          3.0      2.5          2.5  \n",
      "137        3.0     2.5         3.0          2.0      3.0          3.0  \n",
      "3757       3.5     3.0         3.5          3.5      3.5          3.0  \n",
      "3712       3.0     2.5         3.0          2.5      2.0          2.5  \n",
      "1395       3.0     3.5         3.0          3.5      3.5          3.5  \n",
      "1163       3.5     3.5         3.5          3.5      3.5          4.5  \n",
      "2773       3.0     3.0         3.0          3.0      2.5          3.5  \n",
      "1813       3.5     3.5         3.0          3.0      3.0          4.0  \n",
      "1651       3.0     3.5         4.0          4.0      3.0          4.0  \n",
      "2099       3.5     3.5         3.5          3.0      3.0          3.0  \n",
      "516        3.5     3.0         3.0          3.0      2.5          2.5  \n",
      "3716       2.5     2.0         3.0          2.5      2.0          2.5  \n",
      "2495       2.5     2.0         2.5          2.5      2.0          2.5  \n",
      "1549       4.0     3.5         4.0          4.0      4.0          3.0  \n",
      "220        3.5     3.0         3.5          4.0      3.0          2.5  \n",
      "2941       4.0     4.0         3.5          3.5      4.0          4.0  \n",
      "3197       4.5     4.0         4.0          4.5      4.5          4.0  \n",
      "982        4.5     3.5         4.0          4.0      4.5          4.0  \n",
      "3169       3.5     3.5         3.5          3.0      4.0          4.0  \n",
      "3071       3.0     2.5         3.0          2.5      2.0          2.5  \n",
      "1960       3.5     3.0         3.5          3.5      2.5          2.5  \n",
      "3214       2.5     2.5         3.0          3.0      2.5          2.5  \n",
      "2429       2.5     2.5         2.5          2.5      2.5          3.0  \n",
      "725        3.5     2.5         3.0          3.5      2.5          2.5  \n",
      "vectors:\n",
      "   (0, 92)\t0.14319858331669996\n",
      "  (0, 59)\t0.14830555491956335\n",
      "  (0, 40)\t0.44540259523545916\n",
      "  (0, 32)\t0.44491666475869\n",
      "  (0, 65)\t0.2674182187012651\n",
      "  (0, 84)\t0.4054433937262345\n",
      "  (0, 41)\t0.22270129761772958\n",
      "  (0, 74)\t0.14830555491956335\n",
      "  (0, 80)\t0.4610661303157346\n",
      "  (0, 25)\t0.20272169686311725\n",
      "  (1, 12)\t0.09496745947541194\n",
      "  (1, 23)\t0.10085123964518378\n",
      "  (1, 36)\t0.058918286734585885\n",
      "  (1, 71)\t0.08987069726296755\n",
      "  (1, 56)\t0.10085123964518378\n",
      "  (1, 47)\t0.09496745947541194\n",
      "  (1, 6)\t0.07771563086790025\n",
      "  (1, 9)\t0.126827899233121\n",
      "  (1, 22)\t0.07771563086790025\n",
      "  (1, 2)\t0.08135352689624402\n",
      "  (1, 55)\t0.07439449199877671\n",
      "  (1, 89)\t0.25612510314297887\n",
      "  (1, 70)\t0.061099967297162494\n",
      "  (1, 24)\t0.07439449199877671\n",
      "  (1, 87)\t0.05125888322149319\n",
      "  :\t:\n",
      "  (29, 36)\t0.08483090707065846\n",
      "  (29, 56)\t0.03630155683600015\n",
      "  (29, 47)\t0.1709184061517802\n",
      "  (29, 6)\t0.1118954373162796\n",
      "  (29, 22)\t0.0279738593290699\n",
      "  (29, 55)\t0.053556820701071504\n",
      "  (29, 89)\t0.06146174650625802\n",
      "  (29, 70)\t0.1319581559920836\n",
      "  (29, 24)\t0.026778410350535752\n",
      "  (29, 87)\t0.03690142568721101\n",
      "  (29, 48)\t0.1118954373162796\n",
      "  (29, 90)\t0.03073087325312901\n",
      "  (29, 28)\t0.06902105546028545\n",
      "  (29, 19)\t0.04092979483928459\n",
      "  (29, 78)\t0.0439860519973612\n",
      "  (29, 86)\t0.1319581559920836\n",
      "  (29, 60)\t0.16371917935713837\n",
      "  (29, 52)\t0.12487993172336709\n",
      "  (29, 92)\t0.31616286468069876\n",
      "  (29, 59)\t0.2660436664553498\n",
      "  (29, 32)\t0.10232448709821147\n",
      "  (29, 65)\t0.3874649697157157\n",
      "  (29, 74)\t0.04092979483928459\n",
      "  (29, 80)\t0.021207726767664616\n",
      "  (29, 25)\t0.1398692966453495\n",
      "dense:\n",
      " [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20272169686311725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44491666475869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44540259523545916, 0.22270129761772958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14830555491956335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2674182187012651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14830555491956335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4610661303157346, 0.0, 0.0, 0.0, 0.4054433937262345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14319858331669996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.08135352689624402, 0.0, 0.0, 0.0, 0.07771563086790025, 0.0, 0.0, 0.126827899233121, 0.0, 0.0, 0.09496745947541194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056854593958782354, 0.0, 0.0, 0.07771563086790025, 0.10085123964518378, 0.07439449199877671, 0.0, 0.0, 0.0, 0.09587548870473932, 0.0, 0.0, 0.0, 0.056854593958782354, 0.0, 0.0, 0.0, 0.058918286734585885, 0.0, 0.0, 0.0, 0.0, 0.25612510314297887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09496745947541194, 0.1554312617358005, 0.0, 0.09496745947541194, 0.0, 0.09912440613580167, 0.0, 0.0, 0.07439449199877671, 0.10085123964518378, 0.0, 0.0, 0.0, 0.17056378187634705, 0.0, 0.310862523471601, 0.42687517190496477, 0.0, 0.30755329932895914, 0.0, 0.0, 0.0, 0.0, 0.061099967297162494, 0.08987069726296755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1554312617358005, 0.12219993459432499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30549983648581247, 0.05125888322149319, 0.0, 0.25612510314297887, 0.08537503438099295, 0.0, 0.05489677924983696, 0.0, 0.0, 0.0, 0.0, 0.4034049585807351, 0.0, 0.0], [0.0, 0.0, 0.05345836798376058, 0.0, 0.045019201791402765, 0.0, 0.05106786333092738, 0.0, 0.05106786333092738, 0.04167005885595178, 0.0, 0.0, 0.062404244644417885, 0.0, 0.0, 0.05610094827709365, 0.0, 0.0, 0.045019201791402765, 0.0, 0.0, 0.17716530512690068, 0.20427145332370952, 0.0, 0.0, 0.05106786333092738, 0.0, 0.0, 0.06300092142701517, 0.05345836798376058, 0.04888550356652271, 0.05345836798376058, 0.07471965682058712, 0.0, 0.0, 0.06627054641953783, 0.0, 0.0, 0.0, 0.062404244644417885, 0.0, 0.0, 0.05345836798376058, 0.0, 0.0, 0.0, 0.0, 0.12480848928883577, 0.0, 0.13939841459583432, 0.0, 0.0, 0.03256791181369219, 0.0, 0.062404244644417885, 0.0, 0.0, 0.0, 0.05345836798376058, 0.22415897046176134, 0.07471965682058712, 0.0, 0.10213572666185476, 0.1122018965541873, 0.0, 0.4378766662128594, 0.32814549035191126, 0.0, 0.0, 0.05345836798376058, 0.08029902722553633, 0.0, 0.0, 0.1122018965541873, 0.0, 0.3366056896625619, 0.0, 0.15320358999278214, 0.08029902722553633, 0.0, 0.0, 0.0, 0.18721273393325366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036073325130745466, 0.1122018965541873, 0.0, 0.0, 0.07214665026149093, 0.09003840358280553, 0.05905510170896689, 0.04014951361276817, 0.05905510170896689, 0.1988116392586135, 0.4219013447381716, 0.0], [0.0, 0.0, 0.11259261738532989, 0.0, 0.04740913306437042, 0.0, 0.1613366984506177, 0.0, 0.0, 0.0, 0.1865704675100439, 0.1865704675100439, 0.0, 0.0, 0.0, 0.11815835092900348, 0.0, 0.0, 0.0, 0.0786862941094569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13269089403009784, 0.0, 0.0, 0.11259261738532989, 0.03934314705472845, 0.0, 0.23631670185800696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33777785215598966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21511559793415694, 0.07339932432784987, 0.06571709449308179, 0.0, 0.034296842310937464, 0.0, 0.0, 0.05148068493623583, 0.0, 0.0, 0.0, 0.3147451764378276, 0.0786862941094569, 0.0, 0.0, 0.23631670185800696, 0.0, 0.035470938054827865, 0.24683266246908364, 0.0, 0.5583091709195777, 0.05629630869266494, 0.0, 0.0, 0.062190155836681305, 0.0, 0.0, 0.05907917546450174, 0.0, 0.10755779896707847, 0.08456185616782642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07597669452790715, 0.11815835092900348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04228092808391321, 0.0, 0.0, 0.14809959748145018, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10904624162515641, 0.0, 0.0, 0.32661093009032827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133639325620232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27979005895793485, 0.1955336271535584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17045372521020152, 0.23562120578170473, 0.16330546504516413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.488834067883896, 0.0, 0.0, 0.0, 0.0, 0.48991639513549246, 0.2026310542159344, 0.11781060289085236, 0.0, 0.16330546504516413, 0.0, 0.0, 0.2101342634376955, 0.17628892693184045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.06243642160918445, 0.0, 0.020392135200190103, 0.0, 0.0251827499719315, 0.0, 0.0587938071938526, 0.02405664973263268, 0.01962960548671963, 0.027819215531526626, 0.027819215531526626, 0.0, 0.1272437613127158, 0.05563843106305325, 0.0, 0.0, 0.052855192065701655, 0.0212072935521193, 0.0, 0.026427596032850827, 0.0, 0.0, 0.0, 0.023028600759785224, 0.09622659893053072, 0.13909607765763313, 0.0, 0.014838990714978227, 0.0251827499719315, 0.0, 0.0251827499719315, 0.01759917583223802, 0.0, 0.052855192065701655, 0.7804552701148058, 0.018237985988043826, 0.0, 0.0, 0.0, 0.07928278809855248, 0.026427596032850827, 0.0251827499719315, 0.0, 0.08156854080076041, 0.023028600759785224, 0.0, 0.0, 0.0, 0.032833357560755796, 0.0, 0.0, 0.015341837232316316, 0.1272437613127158, 0.0, 0.0, 0.0, 0.0, 0.0251827499719315, 0.03519835166447604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03173407937565136, 0.022082887380056558, 0.0, 0.0, 0.0, 0.037826637846936975, 0.0, 0.0, 0.0, 0.01759917583223802, 0.0, 0.027819215531526626, 0.0, 0.018913318923468488, 0.0, 0.2188558318565259, 0.0, 0.0293969035969263, 0.0, 0.0, 0.0, 0.018913318923468488, 0.01586703968782568, 0.03398627985424901, 0.0, 0.0, 0.0, 0.0, 0.10603646776059651, 0.0, 0.3026131027754958, 0.36164980190984614, 0.0, 0.0, 0.0], [0.0, 0.0, 0.05367828259692093, 0.0, 0.0, 0.0, 0.10255588798861873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1808175989795139, 0.11859607982371623, 0.0, 0.05127794399430936, 0.05633173381738611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34793050470399156, 0.0, 0.0, 0.0, 0.0, 0.11859607982371623, 0.0, 0.0, 0.15550069264970162, 0.0, 0.0, 0.5012876831987134, 0.0, 0.0, 0.0, 0.0, 0.043466849222204576, 0.3926928522971341, 0.18798288119951756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04908660653714176, 0.0, 0.0, 0.0, 0.037513517580435876, 0.037513517580435876, 0.2661726687684099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05367828259692093, 0.0, 0.0, 0.0, 0.0, 0.18756758790217937, 0.0, 0.0, 0.0, 0.08062935772711131, 0.0, 0.388751731624254, 0.04520439974487848, 0.0, 0.0, 0.05127794399430936, 0.0, 0.04031467886355566, 0.06764276667869731, 0.0, 0.0, 0.11266346763477222, 0.0, 0.14488688776784092, 0.0, 0.0, 0.04031467886355566, 0.0, 0.0, 0.0, 0.11859607982371623], [0.06915906403809816, 0.0, 0.0, 0.09035117310285101, 0.04698144240316346, 0.0, 0.0, 0.0, 0.0532937454300393, 0.17394528487186034, 0.0, 0.0, 0.06512424274111694, 0.09396288480632692, 0.0, 0.05854620618232425, 0.0, 0.05854620618232425, 0.0, 0.6238115494923653, 0.05854620618232425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1643673168109559, 0.16736533322159822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16161362337748303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153048791100434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20392464710804592, 0.04698144240316346, 0.1302484854822339, 0.0, 0.0, 0.06512424274111694, 0.0, 0.0, 0.07797644368654566, 0.0, 0.0, 0.3512772370939455, 0.0, 0.10545283527625743, 0.0, 0.0, 0.0, 0.0, 0.041899500352170056, 0.0, 0.12325824311183714, 0.1170924123646485, 0.0, 0.0, 0.12325824311183714, 0.0532937454300393, 0.08379900070434011, 0.0, 0.08080681168874151, 0.0, 0.0, 0.06512424274111694, 0.15988123629011788, 0.1170924123646485, 0.12569850105651015, 0.10545283527625743, 0.03764564406924593, 0.0, 0.1170924123646485, 0.1383181280761963, 0.03764564406924593, 0.2349072120158173, 0.06162912155591857, 0.041899500352170056, 0.0, 0.0, 0.0, 0.0], [0.0, 0.3610501674453485, 0.04854130468383931, 0.1179212971986495, 0.0, 0.04854130468383931, 0.0, 0.16999303759720458, 0.0, 0.0, 0.05362325475519365, 0.05362325475519365, 0.0, 0.08175673419149523, 0.0, 0.0, 0.0, 0.050940822289935274, 0.04087836709574762, 0.0678469950429805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1072465095103873, 0.050940822289935274, 0.14301535183791803, 0.04854130468383931, 0.044389049137570843, 0.04854130468383931, 0.03392349752149025, 0.1072465095103873, 0.10188164457987055, 0.06017502790755808, 0.3515484351994803, 0.05666434586573486, 0.06017502790755808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078614198132433, 0.0, 0.0, 0.0, 0.04637067697712441, 0.09493248443437441, 0.05666434586573486, 0.4289860380415492, 0.029572338062117422, 0.12263510128724285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16961748760745127, 0.135693990085961, 0.0, 0.0, 0.050940822289935274, 0.0, 0.2140928874499602, 0.0, 0.0, 0.0, 0.09708260936767862, 0.07291317886013159, 0.05362325475519365, 0.0, 0.0, 0.10177049256447075, 0.0, 0.0, 0.0, 0.0, 0.2833217293286743, 0.21092906111968818, 0.12263510128724285, 0.0, 0.0, 0.0, 0.0, 0.07291317886013159, 0.06116939641427434, 0.03275532591385208, 0.10188164457987055, 0.0, 0.0, 0.03275532591385208, 0.12263510128724285, 0.2681162737759683, 0.0, 0.05362325475519365, 0.0, 0.08513225646992506, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09177930269560622, 0.0, 0.0, 0.10411052840039683, 0.0, 0.18355860539121244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10898397887035899, 0.0, 0.0, 0.0, 0.27020756910903315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0996614167005475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12039387283188435, 0.26558091814799617, 0.18355860539121244, 0.0, 0.0, 0.13510378455451658, 0.0, 0.21796795774071798, 0.0, 0.07616436684532786, 0.0, 0.0, 0.0, 0.0, 0.06866816054642776, 0.0, 0.0, 0.13510378455451658, 0.0, 0.08185161478476745, 0.0, 0.0, 0.0, 0.2284931005359836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4735737634152638, 0.0, 0.0, 0.0, 0.10411052840039683, 0.0, 0.08185161478476745, 0.0, 0.22062483304916983, 0.0, 0.4574853136927189, 0.13510378455451658, 0.14708322203277988, 0.18355860539121244, 0.0, 0.08185161478476745, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.056480454931852726, 0.045735953159298494, 0.09512841838417972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04756420919208986, 0.06239358095597903, 0.0, 0.10790962246377044, 0.0, 0.04756420919208986, 0.039471839197005344, 0.0, 0.06239358095597903, 0.0, 0.070016926283552, 0.10329815836684961, 0.05395481123188522, 0.0, 0.0, 0.03328123208329762, 0.0, 0.0, 0.0, 0.039471839197005344, 0.06239358095597903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06593205629221705, 0.0, 0.05927242451099776, 0.0, 0.0, 0.0, 0.0, 0.06593205629221705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051649079183424804, 0.0, 0.0, 0.0, 0.07894367839401069, 0.0, 0.42010155770131197, 0.05395481123188522, 0.0, 0.0, 0.0, 0.0, 0.05927242451099776, 0.0, 0.056480454931852726, 0.16967691904329166, 0.06239358095597903, 0.0, 0.0, 0.5131339095610695, 0.0, 0.0, 0.0, 0.08483845952164583, 0.0, 0.572664083752188, 0.2378210459604493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07117392826351607, 0.11433782349517665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14858403393092184, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03662040974112151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04930253926145335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04930253926145335, 0.24914862830297782, 0.0, 0.12888442350386228, 0.0, 0.19699500242690884, 0.05189870331985584, 0.0, 0.0, 0.10207273704815703, 0.0, 0.0, 0.0, 0.0986050785229067, 0.0, 0.1879207654996963, 0.5241579127201959, 0.0, 0.2148073725064371, 0.05484199137715793, 0.0, 0.08975874434192421, 0.0, 0.0, 0.0, 0.05724255293965213, 0.07912739559684719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06566500080896961, 0.03283250040448481, 0.0, 0.0, 0.0, 0.20759481327942336, 0.02960107859222777, 0.0, 0.04930253926145335, 0.0, 0.0, 0.10585238032580577, 0.15569610995956754, 0.0, 0.0, 0.19699500242690884, 0.04930253926145335, 0.0, 0.0, 0.07056825355053718, 0.05484199137715793, 0.17012122841359506, 0.0, 0.0, 0.10968398275431586, 0.0, 0.0986050785229067, 0.38812539452795447, 0.08880323577668332, 0.031701897796189746, 0.0, 0.0, 0.0, 0.34872087575808725, 0.0, 0.0, 0.07056825355053718, 0.0, 0.058239768080021764, 0.0, 0.0], [0.0, 0.0, 0.1646505888137117, 0.08888563458776202, 0.09243876262901127, 0.05488352960457056, 0.0, 0.0, 0.0, 0.299466668469508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11519311837374781, 0.10485859163588898, 0.0, 0.0, 0.11506744365265129, 0.11519311837374781, 0.0, 0.05242929581794449, 0.0, 0.05018875591268752, 0.0, 0.0, 0.11519311837374781, 0.0, 0.0, 0.05018875591268752, 0.0, 0.038355814550883764, 0.0, 0.0, 0.0, 0.07949608720399594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26665690376328605, 0.25094377956343755, 0.06406789689938155, 0.0, 0.05242929581794449, 0.03577866900381608, 0.06406789689938155, 0.0, 0.0, 0.046219381314505634, 0.0, 0.10037751182537503, 0.0, 0.1922036906981447, 0.05488352960457056, 0.038355814550883764, 0.0, 0.0, 0.05242929581794449, 0.0, 0.060629468223377066, 0.1037423406992057, 0.0, 0.11519311837374781, 0.0, 0.0, 0.08243974150669385, 0.060629468223377066, 0.0, 0.057596559186873904, 0.0, 0.0, 0.12125893644675413, 0.31457577490766697, 0.4534185782868162, 0.0, 0.0, 0.0, 0.0, 0.1922036906981447, 0.0, 0.0, 0.08243974150669385, 0.1037423406992057, 0.22221008411816784, 0.2879827959343695, 0.11519311837374781, 0.0, 0.03703501401969464, 0.1386581439435169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.10638726248722652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04183510104171602, 0.13787470357822446, 0.0, 0.0, 0.09191646905214963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02580536703230549, 0.0, 0.0, 0.0, 0.030605396319748884, 0.193513179199509, 0.0, 0.0, 0.15858151386147226, 0.0, 0.0, 0.0, 0.09191646905214963, 0.0, 0.0, 0.10857846107973243, 0.2836993666326041, 0.0, 0.0, 0.0, 0.0, 0.05709801017012558, 0.0, 0.0967565895997545, 0.02667982939905716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30655391790006836, 0.030605396319748884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06121079263949777, 0.0, 0.0, 0.0, 0.03289072323001783, 0.0, 0.7929075693073613, 0.0, 0.0, 0.10224386570526911, 0.0, 0.09191646905214963, 0.09867216969005349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08865445526725967, 0.07376000219770838, 0.0, 0.0, 0.0, 0.0, 0.038402680136474666, 0.0967565895997545], [0.2110636359634866, 0.0, 0.11350560320715941, 0.04595649023953669, 0.047793562055525915, 0.0, 0.05421497934278997, 0.0, 0.10842995868557995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12538888100685527, 0.0, 0.2168599173711599, 0.0, 0.0, 0.07932434190124403, 0.0, 0.0, 0.10842995868557995, 0.0703545453211622, 0.0, 0.0, 0.0, 0.059558233957119185, 0.0, 0.0, 0.1556943874181539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059558233957119185, 0.0, 0.0, 0.0, 0.04595649023953669, 0.0, 0.0, 0.0, 0.05421497934278997, 0.0369972506914829, 0.0, 0.0, 0.03457494696371632, 0.2389678102776296, 0.0, 0.0, 0.4221272719269732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059558233957119185, 0.0, 0.3218270684491117, 0.1990673342206747, 0.0, 0.1407090906423244, 0.11350560320715941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10842995868557995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1278713211692792, 0.03575856316101241, 0.0, 0.0, 0.4169076376998343, 0.35177272660581094, 0.0, 0.2389678102776296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.3847250959376811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12344631529032882, 0.0, 0.0, 0.0, 0.666840260253996, 0.0, 0.22159653043418928, 0.0, 0.11079826521709464, 0.0, 0.07378492349582969, 0.0, 0.05831632995982923, 0.0, 0.0, 0.048273952185995124, 0.0, 0.05831632995982923, 0.0, 0.06221278797921767, 0.0, 0.09654790437199025, 0.0, 0.0, 0.0, 0.22159653043418928, 0.0, 0.07646314882432205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04274723288196457, 0.14482185655798538, 0.0, 0.0, 0.0, 0.13765455830572915, 0.0, 0.0, 0.03216049141342033, 0.04445601735026639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03689246174791484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05539913260854732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11067738524374451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3440841697094492, 0.22228008675133198, 0.0, 0.0, 0.0, 0.0, 0.07929449669251289, 0.03326145271322719, 0.07124410491882477, 0.0, 0.0, 0.0, 0.0, 0.04445601735026639, 0.0, 0.0, 0.0, 0.06544151038238143, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17972093329902974, 0.0, 0.0, 0.05865905780852769, 0.0, 0.0, 0.0, 0.2851814503735257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07888730162387586, 0.03948673050205238, 0.08313203101079825, 0.03594418665980594, 0.046644616304293396, 0.0, 0.07188837331961188, 0.1662640620215965, 0.19743365251026193, 0.02217164310202283, 0.0, 0.0, 0.0, 0.13147883603979313, 0.04156601550539912, 0.0, 0.0, 0.0817507317027513, 0.17569325768166366, 0.18657846521717358, 0.0, 0.31589384401641907, 0.0, 0.0, 0.0, 0.0, 0.13763251881263244, 0.0, 0.0, 0.0, 0.049057884034079235, 0.0, 0.04156601550539912, 0.022922970044108027, 0.0, 0.0, 0.06881625940631622, 0.0, 0.0, 0.11288024005734272, 0.15777460324775172, 0.05259153441591725, 0.0, 0.03594418665980594, 0.0, 0.04156601550539912, 0.04741540011734132, 0.03299509427946268, 0.03948673050205238, 0.0, 0.0, 0.14129645509603422, 0.0, 0.0, 0.03948673050205238, 0.13147883603979313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5722551219192591, 0.22180779473496443, 0.0, 0.0, 0.03594418665980594, 0.0, 0.05651858203841369, 0.16595390041069463, 0.22851234076181065, 0.0, 0.0, 0.0, 0.15234156050787379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04156601550539912], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11035471721496172, 0.0, 0.0, 0.270139805825465, 0.0, 0.0, 0.0, 0.09728390731250379, 0.0, 0.0, 0.0, 0.0, 0.09728390731250379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0680706849169249, 0.0, 0.0, 0.0, 0.0, 0.12761468023368536, 0.0, 0.0, 0.1673256923677837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30123196115042805, 0.0, 0.38284404070105604, 0.0, 0.0, 0.0, 0.1056387632087886, 0.0, 0.0, 0.2310409207212128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3639331946154901, 0.10130050606382988, 0.12123092447575554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2421973251181979, 0.0, 0.0, 0.22070943442992344, 0.0, 0.26970397120873496, 0.0, 0.0, 0.4045559568131024, 0.13485198560436748, 0.11035471721496172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07795238206874272, 0.0, 0.0, 0.08676079107410008, 0.0, 0.0, 0.0, 0.0], [0.0, 0.05383221978666029, 0.0, 0.035163895550812445, 0.0, 0.043424760624722086, 0.0, 0.15207475393601486, 0.041482930070652416, 0.0, 0.0, 0.0, 0.0, 0.07313908505031777, 0.0, 0.0, 0.0, 0.0, 0.07313908505031777, 0.06069551566521893, 0.0, 0.0, 0.041482930070652416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025588135546301485, 0.043424760624722086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6998188572265838, 0.03144931259257125, 0.0, 0.0, 0.0, 0.09114270942550132, 0.0, 0.0, 0.0, 0.035163895550812445, 0.0, 0.0, 0.15207475393601486, 0.0, 0.05661735490249848, 0.10138316929067658, 0.0, 0.05291047324850094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09104327349782838, 0.06069551566521893, 0.0, 0.041482930070652416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06522769338424653, 0.0, 0.0, 0.04557135471275066, 0.0, 0.0, 0.0, 0.0, 0.03261384669212326, 0.0, 0.40884106370342616, 0.0, 0.05069158464533829, 0.0, 0.2488975804239145, 0.04557135471275066, 0.0, 0.027360887950473013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3587523136133559, 0.14391312822117158, 0.0, 0.07615880707631087, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0721742222717893, 0.0, 0.0, 0.0, 0.16374272187542774, 0.0668049181298977, 0.0, 0.0, 0.0, 0.1443484445435786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17988067977617275, 0.0, 0.0, 0.23511788702697609, 0.08570378815298889, 0.1197896209805908, 0.0, 0.08994033988808638, 0.0, 0.0, 0.30013711779288693, 0.3187323380044952, 0.0, 0.08994033988808638, 0.2698210196642591, 0.0, 0.0, 0.0694000153729102, 0.0, 0.0, 0.0, 0.24561408281314162, 0.1117408989834212, 0.0, 0.0, 0.10442493925417999, 0.0721742222717893, 0.0, 0.15674525801798406, 0.0, 0.10004570593096232, 0.0, 0.0, 0.1197896209805908, 0.10624411266816505, 0.08187136093771387, 0.08994033988808638, 0.0, 0.05399987727854085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09467640178907072, 0.09467640178907072, 0.0, 0.2395792419611816, 0.08994033988808638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886968890871572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2159995091141634, 0.17349691348144763, 0.0, 0.0, 0.0, 0.17349691348144763, 0.0, 0.0, 0.06436719897920401, 0.0, 0.0, 0.15030821526133104, 0.28402920536721216], [0.0, 0.0, 0.0, 0.0, 0.2025591915798793, 0.0, 0.0765915039242939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3743751656577273, 0.0, 0.08857075192242578, 0.0, 0.1531830078485878, 0.0, 0.06751973052662644, 0.0, 0.08414011708845852, 0.0, 0.0, 0.0, 0.21995521218461836, 0.0, 0.0, 0.0, 0.04724434317373405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.160353558349675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04884530471385133, 0.0, 0.18718758282886366, 0.0, 0.0, 0.0, 0.0, 0.2801610697666507, 0.05603221395333014, 0.0, 0.0, 0.08414011708845852, 0.0, 0.5556918734013736, 0.28122977625351075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16828023417691704, 0.0, 0.25242035126537554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06751973052662644, 0.0, 0.0, 0.0, 0.0, 0.12043235917287715, 0.15155232910946553, 0.10820543657406421, 0.08414011708845852, 0.0, 0.0, 0.05410271828703211, 0.06751973052662644, 0.08857075192242578, 0.06021617958643857, 0.0, 0.0, 0.0, 0.08857075192242578], [0.0, 0.0, 0.0, 0.11166587512554103, 0.11612962400914098, 0.0, 0.0, 0.08048767169073444, 0.0, 0.1612354753579141, 0.0, 0.0, 0.0, 0.0, 0.07616801813880197, 0.0, 0.0, 0.0, 0.0, 0.048185914606352985, 0.0, 0.0, 0.0, 0.0, 0.06305148606346392, 0.0, 0.0, 0.07235781367428981, 0.04062862637729997, 0.0, 0.06305148606346392, 0.0, 0.048185914606352985, 0.0, 0.0, 0.0, 0.24967476994062932, 0.0, 0.0, 0.0, 0.0, 0.3617890683714491, 0.2757978785524343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39519748451226405, 0.04494827992923243, 0.0, 0.0, 0.0, 0.17419443601371148, 0.0, 0.0, 0.2564230372488836, 0.0, 0.0, 0.0, 0.24092957303176496, 0.0, 0.0, 0.0, 0.0, 0.1303301631976402, 0.060462156620308044, 0.0, 0.5128460744977672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07616801813880197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04652660995194464, 0.11612962400914098, 0.0, 0.051783991435528434, 0.15233603627760395, 0.0, 0.060462156620308044, 0.0], [0.07333906128539554, 0.07333906128539554, 0.0, 0.09581202859754015, 0.19928406675855515, 0.0591603168767955, 0.0, 0.0, 0.1695445123462982, 0.09222929839316087, 0.0, 0.0, 0.0, 0.0, 0.06535400653000069, 0.0, 0.0, 0.0, 0.09964203337927757, 0.0, 0.0, 0.0, 0.11302967489753214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06972069323711, 0.0591603168767955, 0.0, 0.0, 0.08268936634530587, 0.0, 0.0, 0.0, 0.1285362041218495, 0.06906037402305905, 0.0, 0.0, 0.0, 0.3104237935368505, 0.0591603168767955, 0.07333906128539554, 0.0, 0.0, 0.06906037402305905, 0.0, 0.0, 0.038566714111613346, 0.0, 0.0, 0.03604165363781508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05651483744876607, 0.0, 0.26141602612000275, 0.0745509602306916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06535400653000069, 0.0, 0.08268936634530587, 0.0, 0.13070801306000138, 0.0, 0.04443192034036894, 0.06906037402305905, 0.5998356192352977, 0.0, 0.0, 0.0, 0.22605934979506428, 0.0, 0.0, 0.0372754801153458, 0.03992095954337524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44431920340368936, 0.0, 0.0, 0.0, 0.0], [0.14609930212062633, 0.0, 0.0, 0.04771696783242585, 0.0, 0.0, 0.0, 0.06878784833156555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29774647950446753, 0.0, 0.1545994003825715, 0.08443772833341662, 0.030919880076514302, 0.024812206625372292, 0.04118152899733027, 0.030919880076514302, 0.0, 0.0, 0.29219860424125266, 0.0, 0.0, 0.0, 0.0, 0.06944556179734244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030919880076514302, 0.0, 0.0, 0.06878784833156555, 0.03652482553015658, 0.10318177249734833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026943107989746095, 0.10318177249734833, 0.06878784833156555, 0.0, 0.03841452234346002, 0.0, 0.032548053443388375, 0.01794971312513479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04118152899733027, 0.07304965106031316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24708917398398159, 0.0, 0.0, 0.0, 0.022128291662835378, 0.0, 0.4481014132581801, 0.12406103312686147, 0.0, 0.0, 0.05629181888894441, 0.0, 0.0, 0.0, 0.11929027097666836, 0.0, 0.2164391605356001, 0.03652482553015658, 0.0, 0.024812206625372292, 0.0, 0.4868224165823783, 0.032548053443388375, 0.0, 0.3617129307410598, 0.032548053443388375], [0.0, 0.0, 0.06197194324126279, 0.0, 0.2087551508516896, 0.0, 0.05920073595883403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08661922363396325, 0.0, 0.2738399655093734, 0.0, 0.0, 0.056670821923808005, 0.47360588767067224, 0.06845999137734335, 0.0, 0.0, 0.0, 0.0, 0.3098597162063139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07682454022028236, 0.10036554757545488, 0.0, 0.0, 0.0, 0.1776022078765021, 0.04039961825938704, 0.0, 0.06845999137734335, 0.03775455290774488, 0.0, 0.0, 0.28335410961904, 0.0, 0.1446850120187935, 0.0, 0.0, 0.0, 0.0, 0.05920073595883403, 0.0, 0.06845999137734335, 0.0, 0.05434352661426589, 0.0, 0.0, 0.0, 0.13963071485070122, 0.0, 0.0, 0.19510611230024102, 0.12992883545094489, 0.13007074153349402, 0.0, 0.05920073595883403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45524759536722903, 0.0, 0.039047017662359684, 0.12545467483436534, 0.0, 0.0, 0.0, 0.2090911247239422, 0.0, 0.06845999137734335, 0.0, 0.0, 0.0, 0.05434352661426589, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.11256588592101303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.094795754607502, 0.07866761260162755, 0.0, 0.12435078160344837, 0.0, 0.0, 0.0, 0.10753226285705762, 0.0, 0.0, 0.06632969544100568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2628059684038405, 0.0, 0.0, 0.11256588592101303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189591509215004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07866761260162755, 0.0, 0.41863246388952674, 0.0, 0.0, 0.0, 0.28370013305055736, 0.0, 0.0, 0.41863246388952674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08454177969839877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16908355939679753, 0.07092503326263934, 0.0, 0.0, 0.0, 0.2790883092596845, 0.15191731265318953, 0.47397877303750996, 0.0, 0.0, 0.0, 0.13954415462984224, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.15007953344696937, 0.0, 0.0, 0.04778946927552668, 0.038994973893882956, 0.05526395240770936, 0.05526395240770936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10499889242056493, 0.0, 0.24473012553278, 0.1574983386308474, 0.0, 0.0, 0.0, 0.09149442010416542, 0.0, 0.0, 0.05249944621028246, 0.029478231538256305, 0.35018557804292855, 0.04574721005208271, 0.15007953344696937, 0.03496144650468286, 0.0, 0.0, 0.0, 0.03623046769645606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08101953758672628, 0.32023047036457897, 0.0, 0.0, 0.0, 0.09783711051628667, 0.0, 0.0, 0.2438172454410759, 0.0, 0.05839809104154861, 0.13724163015624813, 0.0, 0.0, 0.05002651114898979, 0.10488433951404856, 0.5244216975702428, 0.0, 0.0, 0.0, 0.0, 0.03152049076170028, 0.13160554104912395, 0.0, 0.0, 0.0, 0.037572042808822974, 0.0, 0.11052790481541871, 0.0, 0.0, 0.0, 0.11052790481541871, 0.0, 0.07514408561764595, 0.0, 0.0, 0.08425822505544442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1260819630468011, 0.10127259790549019, 0.36749612347197724, 0.0, 0.0, 0.0, 0.0, 0.05526395240770936, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.07008959578581257, 0.0, 0.0, 0.0, 0.23851994856070663, 0.0648753746260874, 0.0919418391079067, 0.0919418391079067, 0.09715606026763188, 0.0, 0.0, 0.08734257009179527, 0.0, 0.0, 0.07008959578581257, 0.17449456016820242, 0.0, 0.0919418391079067, 0.0, 0.0, 0.0, 0.07950664952023555, 0.0919418391079067, 0.0, 0.04904250787712202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08734257009179527, 0.0, 0.18082831682992787, 0.0, 0.0, 0.0, 0.0, 0.17468514018359055, 0.0, 0.0, 0.06739551701297278, 0.0, 0.0, 0.09715606026763188, 0.0, 0.2712836451842359, 0.3886242410705275, 0.0, 0.05070440353843841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058164853389400806, 0.0, 0.0, 0.1590132990404711, 0.0, 0.3677673564316268, 0.10488037007683246, 0.21895023706555594, 0.0, 0.0, 0.1664567675238763, 0.06250806473990608, 0.1838836782158134, 0.0919418391079067, 0.0, 0.0, 0.08734257009179527, 0.3677673564316268, 0.23851994856070663, 0.0, 0.0, 0.0, 0.07008959578581257, 0.0, 0.0, 0.0, 0.08734257009179527, 0.0, 0.0, 0.1123238385602377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07298341235518531, 0.0], [0.09651583585265194, 0.14477375377897791, 0.0, 0.03152269016930841, 0.03278278303915897, 0.11678443927278734, 0.0, 0.09088498824922432, 0.0, 0.0, 0.043003663095826816, 0.043003663095826816, 0.0, 0.26226226431327176, 0.0, 0.0, 0.037187391540356524, 0.0, 0.03278278303915897, 0.13602630660021509, 0.0, 0.0, 0.037187391540356524, 0.0, 0.035598206840872774, 0.1487495661614261, 0.043003663095826816, 0.0, 0.1376309745325175, 0.03892814642426245, 0.035598206840872774, 0.0, 0.027205261320043018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40898244712150944, 0.0, 0.0, 0.0, 0.0, 0.03152269016930841, 0.0, 0.0, 0.0, 0.0, 0.12688663392102462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22721247062306082, 0.0, 0.08161578396012906, 0.027205261320043018, 0.0, 0.0, 0.0, 0.08600732619165363, 0.0, 0.0, 0.04085246167137193, 0.0, 0.03892814642426245, 0.029236697709431467, 0.0, 0.0, 0.0, 0.24484735188038714, 0.0, 0.0, 0.07437478308071305, 0.0, 0.04544249412461216, 0.535662261132456, 0.1966966982349538, 0.1363274823738365, 0.0, 0.07437478308071305, 0.2451147700282316, 0.0, 0.0981107218196133, 0.0, 0.0, 0.0, 0.0, 0.2364159180492833, 0.0, 0.0, 0.029236697709431467, 0.0, 0.0, 0.06827259726276864, 0.0], [0.0, 0.0, 0.0, 0.18970113556109539, 0.0, 0.11713330211203224, 0.1118954373162796, 0.0, 0.0279738593290699, 0.0, 0.03234909393340689, 0.03234909393340689, 0.0, 0.0, 0.0, 0.0, 0.19581701530348927, 0.0, 0.0, 0.04092979483928459, 0.0, 0.0, 0.0279738593290699, 0.0, 0.026778410350535752, 0.1398692966453495, 0.0, 0.0, 0.06902105546028545, 0.17569995316804835, 0.026778410350535752, 0.0, 0.10232448709821147, 0.0, 0.03073087325312901, 0.0, 0.08483090707065846, 0.03418368123035603, 0.03630155683600015, 0.0, 0.0, 0.0, 0.08784997658402417, 0.03630155683600015, 0.2134137775062323, 0.16067046210321453, 0.0, 0.1709184061517802, 0.1118954373162796, 0.09544925581010251, 0.0, 0.0, 0.12487993172336709, 0.24660534744891643, 0.1025510436910681, 0.053556820701071504, 0.03630155683600015, 0.23928576861249223, 0.02928332552800806, 0.2660436664553498, 0.16371917935713837, 0.0, 0.0, 0.0, 0.0, 0.3874649697157157, 0.025678703893311883, 0.09219261975938703, 0.0, 0.11713330211203224, 0.1319581559920836, 0.0, 0.19409456360044136, 0.03073087325312901, 0.04092979483928459, 0.15365436626564505, 0.0, 0.0, 0.0439860519973612, 0.0, 0.021207726767664616, 0.049321069489783285, 0.03418368123035603, 0.0, 0.0, 0.09219261975938703, 0.1319581559920836, 0.03690142568721101, 0.05928053712763102, 0.06146174650625802, 0.03073087325312901, 0.0, 0.31616286468069876, 0.0, 0.12939637573362756, 0.1539511819907642, 0.03234909393340689, 0.0, 0.0, 0.03234909393340689]]\n",
      "feature:\n",
      " ['able' 'activity' 'agree' 'also' 'always' 'another' 'bad' 'benefit'\n",
      " 'best' 'better' 'ca' 'ca nt' 'change' 'class' 'come' 'could' 'day'\n",
      " 'different' 'every' 'example' 'experience' 'family' 'feel' 'finish'\n",
      " 'first' 'friend' 'fun' 'future' 'get' 'give' 'go' 'going' 'good' 'grade'\n",
      " 'great' 'group' 'help' 'high' 'high school' 'home' 'idea' 'important'\n",
      " 'job' 'kid' 'know' 'learn' 'learning' 'let' 'life' 'like' 'look' 'lot'\n",
      " 'make' 'many' 'may' 'need' 'negative' 'never' 'new' 'nt' 'one' 'online'\n",
      " 'opinion' 'others' 'parent' 'people' 'person' 'play' 'positive' 'problem'\n",
      " 'reason' 'right' 'said' 'say' 'school' 'see' 'show' 'someone' 'something'\n",
      " 'sport' 'student' 'take' 'talk' 'teach' 'teacher' 'tell' 'thing' 'think'\n",
      " 'time' 'try' 'use' 'using' 'want' 'way' 'well' 'work' 'working' 'world'\n",
      " 'would' 'year']\n",
      "all:\n",
      " [['friend', 'good', 'idea', 'important', 'nt', 'people', 'school', 'student', 'teacher', 'want'], ['agree', 'bad', 'better', 'change', 'example', 'feel', 'finish', 'first', 'get', 'good', 'help', 'important', 'let', 'life', 'look', 'make', 'need', 'negative', 'one', 'opinion', 'others', 'people', 'reason', 'right', 'someone', 'something', 'thing', 'think', 'try', 'use', 'want', 'world'], ['agree', 'always', 'bad', 'best', 'better', 'change', 'could', 'every', 'family', 'feel', 'friend', 'get', 'give', 'go', 'going', 'good', 'group', 'home', 'job', 'let', 'like', 'make', 'may', 'new', 'nt', 'one', 'opinion', 'others', 'people', 'person', 'problem', 'reason', 'say', 'see', 'someone', 'something', 'talk', 'time', 'try', 'want', 'way', 'well', 'work', 'working', 'world', 'would'], ['agree', 'always', 'bad', 'ca', 'ca nt', 'could', 'example', 'get', 'going', 'good', 'great', 'job', 'life', 'like', 'look', 'make', 'need', 'nt', 'one', 'others', 'people', 'person', 'positive', 'problem', 'said', 'see', 'someone', 'something', 'time', 'try', 'work', 'would'], ['better', 'change', 'feel', 'going', 'good', 'make', 'many', 'may', 'school', 'sport', 'student', 'take', 'teach', 'thing', 'think'], ['activity', 'also', 'another', 'benefit', 'best', 'better', 'ca', 'ca nt', 'class', 'come', 'different', 'every', 'experience', 'first', 'friend', 'fun', 'get', 'give', 'going', 'good', 'great', 'group', 'help', 'idea', 'important', 'job', 'know', 'learn', 'like', 'make', 'many', 'new', 'nt', 'people', 'person', 'reason', 'school', 'show', 'something', 'student', 'talk', 'thing', 'think', 'time', 'way', 'work', 'working'], ['agree', 'bad', 'class', 'come', 'day', 'different', 'get', 'grade', 'help', 'home', 'know', 'learn', 'learning', 'need', 'nt', 'one', 'online', 'problem', 'school', 'something', 'student', 'take', 'teacher', 'thing', 'think', 'use', 'want', 'work', 'year'], ['able', 'also', 'always', 'best', 'better', 'change', 'class', 'could', 'different', 'example', 'experience', 'get', 'give', 'help', 'learn', 'make', 'many', 'may', 'never', 'one', 'others', 'people', 'reason', 'said', 'say', 'show', 'someone', 'something', 'student', 'teach', 'teacher', 'tell', 'thing', 'think', 'time', 'use', 'using', 'want', 'way', 'well', 'work'], ['activity', 'agree', 'also', 'another', 'benefit', 'ca', 'ca nt', 'class', 'different', 'every', 'example', 'fun', 'future', 'get', 'give', 'go', 'going', 'good', 'grade', 'great', 'group', 'help', 'high', 'high school', 'know', 'life', 'like', 'look', 'lot', 'make', 'many', 'nt', 'one', 'others', 'people', 'problem', 'reason', 'right', 'school', 'sport', 'student', 'take', 'thing', 'think', 'time', 'try', 'want', 'way', 'well', 'working', 'would'], ['class', 'day', 'every', 'going', 'group', 'learn', 'lot', 'make', 'many', 'negative', 'new', 'one', 'people', 'positive', 'reason', 'school', 'student', 'teacher', 'thing', 'time', 'use', 'using', 'want', 'way', 'work'], ['agree', 'also', 'always', 'class', 'come', 'day', 'every', 'example', 'family', 'finish', 'first', 'friend', 'get', 'good', 'grade', 'home', 'important', 'learning', 'need', 'nt', 'online', 'opinion', 'play', 'problem', 'reason', 'right', 'school', 'something', 'student', 'take', 'think', 'time', 'would'], ['better', 'could', 'future', 'get', 'go', 'good', 'grade', 'help', 'idea', 'job', 'kid', 'learn', 'learning', 'life', 'make', 'many', 'nt', 'one', 'parent', 'people', 'play', 'reason', 'right', 'school', 'see', 'something', 'sport', 'student', 'teach', 'tell', 'thing', 'think', 'time', 'want', 'work', 'world'], ['agree', 'also', 'always', 'another', 'better', 'could', 'day', 'example', 'experience', 'feel', 'first', 'future', 'go', 'good', 'help', 'know', 'learn', 'learning', 'life', 'like', 'look', 'many', 'need', 'never', 'new', 'nt', 'opinion', 'parent', 'people', 'play', 'reason', 'right', 'say', 'show', 'someone', 'something', 'teach', 'thing', 'think', 'time', 'try', 'use', 'want', 'way'], ['also', 'day', 'different', 'experience', 'get', 'good', 'grade', 'help', 'idea', 'kid', 'know', 'like', 'lot', 'make', 'new', 'nt', 'school', 'something', 'student', 'teach', 'tell', 'thing', 'want', 'way', 'would', 'year'], ['able', 'agree', 'also', 'always', 'bad', 'best', 'come', 'day', 'example', 'feel', 'finish', 'future', 'go', 'idea', 'know', 'life', 'like', 'make', 'many', 'negative', 'others', 'people', 'person', 'positive', 'problem', 'someone', 'thing', 'think', 'use', 'using', 'way'], ['also', 'better', 'class', 'could', 'different', 'example', 'family', 'first', 'fun', 'get', 'go', 'great', 'help', 'know', 'learn', 'like', 'make', 'many', 'one', 'play', 'school', 'student', 'take', 'thing', 'think', 'time', 'way', 'world'], ['bad', 'better', 'class', 'example', 'experience', 'family', 'feel', 'finish', 'friend', 'fun', 'future', 'get', 'good', 'grade', 'help', 'high', 'high school', 'idea', 'learn', 'like', 'lot', 'make', 'need', 'new', 'nt', 'one', 'opinion', 'parent', 'people', 'person', 'play', 'reason', 'say', 'school', 'student', 'take', 'teacher', 'thing', 'think', 'time', 'want', 'year'], ['bad', 'better', 'class', 'every', 'get', 'grade', 'help', 'like', 'lot', 'need', 'new', 'people', 'person', 'play', 'school', 'someone', 'sport', 'talk', 'teach', 'teacher', 'want', 'work'], ['activity', 'also', 'another', 'benefit', 'best', 'class', 'every', 'example', 'feel', 'get', 'give', 'group', 'help', 'idea', 'know', 'let', 'like', 'look', 'make', 'nt', 'one', 'opinion', 'reason', 'say', 'something', 'student', 'talk', 'teacher', 'tell', 'think', 'work', 'working', 'would'], ['always', 'best', 'better', 'class', 'future', 'go', 'going', 'good', 'great', 'high', 'high school', 'idea', 'important', 'know', 'life', 'like', 'make', 'many', 'need', 'never', 'one', 'online', 'opinion', 'others', 'people', 'right', 'said', 'school', 'see', 'take', 'think', 'time', 'want', 'work', 'would', 'year'], ['always', 'bad', 'change', 'come', 'day', 'every', 'experience', 'first', 'get', 'job', 'make', 'may', 'nt', 'one', 'others', 'people', 'person', 'say', 'see', 'take', 'thing', 'think', 'time', 'try', 'want', 'way', 'well', 'work', 'year'], ['also', 'always', 'benefit', 'better', 'come', 'example', 'first', 'future', 'get', 'go', 'good', 'help', 'important', 'job', 'life', 'like', 'many', 'negative', 'one', 'people', 'person', 'positive', 'show', 'want', 'way', 'work', 'working', 'would'], ['able', 'activity', 'also', 'always', 'another', 'best', 'better', 'come', 'every', 'feel', 'get', 'give', 'good', 'help', 'high', 'important', 'job', 'kid', 'learning', 'like', 'make', 'opinion', 'parent', 'people', 'said', 'school', 'show', 'something', 'sport', 'student', 'teacher', 'think', 'time', 'work'], ['able', 'also', 'benefit', 'class', 'could', 'day', 'different', 'every', 'example', 'experience', 'finish', 'get', 'great', 'high', 'high school', 'home', 'learn', 'learning', 'let', 'like', 'lot', 'make', 'one', 'online', 'school', 'something', 'student', 'take', 'teacher', 'time', 'use', 'using', 'way', 'work', 'working', 'would', 'year'], ['agree', 'always', 'bad', 'example', 'family', 'first', 'friend', 'fun', 'going', 'kid', 'know', 'life', 'like', 'lot', 'make', 'need', 'never', 'opinion', 'parent', 'person', 'reason', 'say', 'school', 'see', 'someone', 'tell', 'think', 'time', 'want', 'well', 'would'], ['another', 'every', 'example', 'family', 'friend', 'get', 'home', 'job', 'many', 'nt', 'online', 'people', 'positive', 'something', 'thing', 'think', 'using', 'want', 'way', 'world'], ['another', 'best', 'better', 'ca', 'ca nt', 'different', 'example', 'experience', 'first', 'future', 'get', 'give', 'go', 'going', 'good', 'help', 'know', 'learn', 'like', 'make', 'may', 'need', 'new', 'nt', 'one', 'people', 'person', 'reason', 'said', 'show', 'something', 'take', 'think', 'time', 'try', 'well'], ['always', 'best', 'better', 'ca', 'ca nt', 'change', 'could', 'every', 'example', 'family', 'friend', 'fun', 'get', 'great', 'help', 'important', 'know', 'let', 'like', 'look', 'make', 'nt', 'opinion', 'parent', 'people', 'person', 'problem', 'reason', 'right', 'said', 'see', 'show', 'someone', 'take', 'tell', 'time', 'would'], ['able', 'activity', 'also', 'always', 'another', 'benefit', 'ca', 'ca nt', 'class', 'day', 'every', 'example', 'feel', 'first', 'friend', 'fun', 'get', 'give', 'go', 'good', 'home', 'know', 'like', 'never', 'nt', 'one', 'parent', 'play', 'problem', 'reason', 'school', 'someone', 'sport', 'student', 'take', 'talk', 'teacher', 'tell', 'think', 'want', 'work', 'would'], ['also', 'another', 'bad', 'best', 'ca', 'ca nt', 'day', 'example', 'feel', 'first', 'friend', 'get', 'give', 'go', 'good', 'great', 'help', 'high', 'high school', 'job', 'kid', 'know', 'learn', 'let', 'life', 'like', 'make', 'many', 'may', 'need', 'negative', 'never', 'new', 'nt', 'one', 'people', 'person', 'play', 'problem', 'reason', 'said', 'say', 'school', 'see', 'something', 'student', 'take', 'talk', 'tell', 'thing', 'think', 'time', 'try', 'use', 'want', 'well', 'work', 'working', 'year']]\n"
     ]
    }
   ],
   "source": [
    "dataframe, y, clean_data, vectors, denselist, feature_names, all_keywords = tfidf_pipeline(train_data_path)\n",
    "print('dataframe:\\n',dataframe)\n",
    "print('y:\\n',y)\n",
    "print('clean:\\n',clean_data)\n",
    "print('vectors:\\n',vectors)\n",
    "print('dense:\\n',denselist)\n",
    "print('feature:\\n',feature_names)\n",
    "print('all:\\n',all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ce97344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv('./tfidfDataInstances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc5815",
   "metadata": {},
   "source": [
    "# Deep Learning: Training with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e075eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "#Bringing the data\n",
    "train_data_path = ('./feedback-prize-english-language-learning/train.csv')\n",
    "test_data_path = ('./feedback-prize-english-language-learning/test.csv')\n",
    "\n",
    "raw_train_ds = load_data(train_data_path)\n",
    "raw_test_ds = load_data(test_data_path)\n",
    "\n",
    "def load_data(path):\n",
    "    corpus = pd.read_csv(path)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25ca20",
   "metadata": {},
   "source": [
    "This layer has basic options for managing text in a Keras model. It transforms a batch of strings (one example = one string) into either a list of token indices (one example = 1D tensor of integer token indices) or a dense representation (one example = 1D tensor of float values representing data about the example's tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19e36e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(raw_train_ds['full_text'])\n",
    "max_features = 30000  # Maximum vocab size.\n",
    "max_len = 800  # Sequence length to pad the outputs to.\n",
    "\n",
    "# Create the layer.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e9d11",
   "metadata": {},
   "source": [
    "The vocabulary for the layer must be either supplied on construction or learned via adapt(). When this layer is adapted, it will analyze the dataset, determine the frequency of individual string values, and create a vocabulary from them. This vocabulary can have unlimited size or be capped, depending on the configuration options for this layer; if there are more unique values in the input than the maximum vocabulary size, the most frequent terms will be used to create the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c8a9bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_dataset)\n",
    "# print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "14ecc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# The model\n",
    "model = tf.keras.models.Sequential()\n",
    "# Start by creating an explicit input layer. It needs to have a shape of\n",
    "# (1,) (because we need to guarantee that there is exactly one string\n",
    "# input per batch), and the dtype needs to be 'string'.\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "# The first layer in our model is the vectorization layer. After this\n",
    "# layer, we have a tensor of shape (batch_size, max_len) containing\n",
    "# vocab indices.\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "input_data = [raw_train_ds['full_text']]\n",
    "test = [raw_test_ds['full_text']]\n",
    "X_train = model.predict(input_data)\n",
    "X_test = model.predict(test)\n",
    "# print(X_test)\n",
    "Y_train = raw_train_ds[['cohesion','syntax','vocabulary','phraseology','grammar','conventions']]\n",
    "# print(df['full_text'])\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "00cee5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 8)           240008    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, None, 8)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_25  (None, 8)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,017\n",
      "Trainable params: 240,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 8.2775 - accuracy: 1.7046e-04\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.4513 - accuracy: 0.0024\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.7474 - accuracy: 0.0024\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.0024\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.0024\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.0024\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.0024\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.0024\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.0024\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.0024\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 8\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "#   layers.Dense(512, input_shape=(max_features,)),\n",
    "#   layers.Activation('relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a31bb5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eba715dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Loss:  0.0\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d0b7d",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "da8b5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "loss = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training loss and accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss/Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81d64c",
   "metadata": {},
   "source": [
    "The desired behavior is for the training loss to decrease, while the accuracy increases. Deep Learning is a suitable approach when we have a large amount of data, since the dataset is not big enough, the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a2eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
