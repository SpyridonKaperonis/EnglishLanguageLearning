{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7144211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbad45b",
   "metadata": {},
   "source": [
    "1. Data visualization\n",
    "2. Data pre-processing\n",
    "3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50daf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = ('./feedback-prize-english-language-learning/train.csv')\n",
    "test_data_path = ('./feedback-prize-english-language-learning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    corpus = pd.read_csv(path)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620e3b2",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133f5c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaaaf4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eab72c",
   "metadata": {},
   "source": [
    "### Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75586674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c54dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_data(data):\n",
    "    lowercase = np.char.lower(data)\n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-.,/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    no_punctuation = data\n",
    "    for i in symbols:\n",
    "        no_punctuation = np.char.replace(no_punctuation, i, ' ')\n",
    "        no_punctuation = np.char.replace(no_punctuation, \"'\", \"\")        \n",
    "        \n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2240bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_words(data):\n",
    "    newData = []\n",
    "    for i in data:\n",
    "        if i != str(i):\n",
    "            num = num2words(i)\n",
    "            newData.append(num)\n",
    "        else:\n",
    "            newData.append(i)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fa7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in data if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc4ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(data):\n",
    "    a = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(i)\n",
    "        a.append(lemmatized_word)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996b7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanning(data):\n",
    "    df = data\n",
    "    # Loop through data and clean it.\n",
    "    for i in data['full_text']:\n",
    "       \n",
    "        ndata = tokenize_data(i)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        ndata = lowercase_data(ndata)\n",
    "        ndata = numbers_to_words(ndata)\n",
    "        ndata = remove_stop_words(ndata)\n",
    "        ndata = lemmatize_words(ndata)\n",
    "        ndata = numbers_to_words(ndata)\n",
    "        ndata = ' '.join(ndata)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        \n",
    "        df = df.replace(i, ndata)\n",
    "\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53525f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_validation(data):    \n",
    "    train_d, val_d = train_test_split(data, test_size=0.2, random_state=1)\n",
    "    train_d = pd.DataFrame(train_d)\n",
    "    val_d = pd.DataFrame(val_d)\n",
    "    return train_d, val_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc3805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(data):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=100,\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.8,\n",
    "                                 ngram_range=(1,3))\n",
    "    vectors = vectorizer.fit_transform(data)\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    all_keywords = []\n",
    "    for i in denselist:\n",
    "        x = 0\n",
    "        keywords = []\n",
    "        for word in i:\n",
    "            if word > 0:\n",
    "                keywords.append(feature_names[x])\n",
    "            x=x+1\n",
    "        all_keywords.append(keywords)\n",
    "    \n",
    "            \n",
    "    \n",
    "    return vectors, denselist, feature_names, all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6eaf52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_pipeline(data):\n",
    "    dataf = load_data(data)\n",
    "\n",
    "    train_data, validation_data = split_test_validation_byID(dataf)\n",
    "\n",
    "    clean_data = data_cleanning(train_data[:30])\n",
    "    vectors, denselist, feature_names, all_keywords = tf_idf(clean_data['full_text'])\n",
    "    y = train_data[['vocabulary', 'syntax']]\n",
    "    \n",
    "    # Convert vectoried data with keywords into a dataframe\n",
    "    data=[]\n",
    "    for i in range(len(all_keywords)):\n",
    "        data.insert(i, {'words':all_keywords[i],'vectors':denselist[i],})\n",
    "    dataframe = pd.DataFrame(data)\n",
    "\n",
    "    return dataframe, y, clean_data, vectors, denselist, feature_names, all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d9c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe, y, clean_data, vectors, denselist, feature_names, all_keywords = tfidf_pipeline(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b649623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce97344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv('./tfidfDataInstances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dfec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6ab66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
