{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7144211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7fa8f",
   "metadata": {},
   "source": [
    "1. Data visualization\n",
    "2. Data pre-processing\n",
    "3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50daf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = ('./feedback-prize-english-language-learning/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    corpus = pd.read_csv('./feedback-prize-english-language-learning/train.csv')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa2d0c",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d32b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e223b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear friend\\n\\nmy name is STUDENT_NAME\\n\\nam coming from LOCATION_NAME.\\n\\ni speak LOCATION_NAME and LANGUAGE_NAME.\\n\\ni am a student to SCHOOL_NAME to 8grade.\\n\\nThe community is very important. Because he teacher people a good idea.\\n\\nex: my idea is to respect the teacher and other people.\\n\\nI don't no speak English good.\\n\\nBecause to my contry no English.\\n\\ni want to be a good student in English and other .\\n\\nThank's\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'][2352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13db2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fafb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b4f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc80c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20451b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_data(data):\n",
    "    lowercase = np.char.lower(data)\n",
    "    return lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f7df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-.,/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    no_punctuation = data\n",
    "    for i in symbols:\n",
    "        no_punctuation = np.char.replace(data, i, ' ')\n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c38f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_words(data):\n",
    "    newData = []\n",
    "    for i in data:\n",
    "        if i != str(i):\n",
    "            num = num2words(i)\n",
    "            newData.append(num)\n",
    "        else:\n",
    "            newData.append(i)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21076750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in data if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d5ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(data):\n",
    "    a = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(i)\n",
    "        a.append(lemmatized_word)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996b7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanning(data):\n",
    "    df = data\n",
    "    # Loop through data and clean it.\n",
    "    for i in data['full_text']:\n",
    "        ndata = tokenize_data(i)\n",
    "        ndata = lowercase_data(ndata)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        ndata = numbers_to_words(ndata)\n",
    "        ndata = remove_stop_words(ndata)\n",
    "        ndata = remove_punctuation(ndata)\n",
    "        ndata = lemmatize_words(ndata)\n",
    "        ndata = ' '.join(ndata)\n",
    "        \n",
    "        df = df.replace(i, ndata)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc3805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(data):\n",
    "    tfidfVectorizer = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
    "    tfidf = tfidfVectorizer.fit_transform(data)\n",
    "    df = pd.DataFrame(tfidf.toarray())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b454e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_validation_byID(data):    \n",
    "    train_d, val_d = train_test_split(data, test_size=0.2, random_state=1)\n",
    "    train_d = pd.DataFrame(train_d)\n",
    "    val_d = pd.DataFrame(val_d)\n",
    "    return train_d, val_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(x,y):\n",
    "    linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d5d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfor_Vocabulary_pipeline(data):\n",
    "    dataf = load_data(data)\n",
    "    \n",
    "    # x_train, x_val, y_train, y_val = split_test_validation(train_dataPath)\n",
    "    train_data, validation_data = split_test_validation_byID(dataf)\n",
    " \n",
    "    df = data_cleanning(train_data)\n",
    "    return df.head()\n",
    "     #X = tf_idf(df['full_text'])\n",
    "#     Y = train_data['vocabulary']\n",
    "    \n",
    "#     svm_clf = SVC()\n",
    "#     svm_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b905da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = modelfor_Vocabulary_pipeline(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0ea0bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>AEE8A576989C</td>\n",
       "      <td>dear friend name student_name coming location_...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>DA00F2B25B8C</td>\n",
       "      <td>according author '' world constantly trying ma...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>589CEB00ED37</td>\n",
       "      <td>good behavior trying influence per swaying oth...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>5C9B1FB411EB</td>\n",
       "      <td>said positive attitude key success life . agre...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>AEF788DA28DE</td>\n",
       "      <td>think principal change school policy many stud...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "2352  AEE8A576989C  dear friend name student_name coming location_...   \n",
       "3059  DA00F2B25B8C  according author '' world constantly trying ma...   \n",
       "1142  589CEB00ED37  good behavior trying influence per swaying oth...   \n",
       "1195  5C9B1FB411EB  said positive attitude key success life . agre...   \n",
       "2354  AEF788DA28DE  think principal change school policy many stud...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
       "2352       2.5     2.0         3.0          2.5      2.0          2.5  \n",
       "3059       3.5     3.0         3.5          3.5      2.5          3.0  \n",
       "1142       3.5     3.5         4.0          3.5      3.0          3.0  \n",
       "1195       3.5     3.0         3.0          3.5      3.0          3.5  \n",
       "2354       3.0     3.0         4.0          3.0      3.0          3.5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba3fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
